{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerank relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import html\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from FlagEmbedding import FlagReranker, FlagModel\n",
    "\n",
    "from typing import Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most recent CSV file\n",
    "list_of_files = glob.glob('out/full_labeled_comments_*.parquet')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "comments = pd.read_parquet(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['text'] = comments['text'].apply(html.unescape)\n",
    "pairs = comments.text.apply(lambda comment: ['product market fit', comment]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BAAI/bge-base-en-v1.5 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.911517</td>\n",
       "      <td>Laziness is the enemy.  I spend a lot of time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.037979</td>\n",
       "      <td>I just stuck it on a public server, behind a B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.933453</td>\n",
       "      <td>Thanks for answering. I'm not NetBeans fan mys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.574196</td>\n",
       "      <td>&gt; it misses the main point of the new table fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.169174</td>\n",
       "      <td>&gt; If I'm already going through the trouble of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>None</td>\n",
       "      <td>As a long-time reader of Daring Fireball I lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>None</td>\n",
       "      <td>Funny..but I was expecting them to have it all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>None</td>\n",
       "      <td>Agreed, you should make a decision on who is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>None</td>\n",
       "      <td>Very nice, thank you!&lt;p&gt;Unhelpfully my only pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>None</td>\n",
       "      <td>TL;DR: Thank you for confirming some mismatch ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3246 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "0    -10.911517  Laziness is the enemy.  I spend a lot of time ...\n",
       "1    -11.037979  I just stuck it on a public server, behind a B...\n",
       "2    -10.933453  Thanks for answering. I'm not NetBeans fan mys...\n",
       "3    -10.574196  > it misses the main point of the new table fo...\n",
       "4     -6.169174  > If I'm already going through the trouble of ...\n",
       "...         ...                                                ...\n",
       "3241       None  As a long-time reader of Daring Fireball I lea...\n",
       "3242       None  Funny..but I was expecting them to have it all...\n",
       "3243       None  Agreed, you should make a decision on who is t...\n",
       "3244       None  Very nice, thank you!<p>Unhelpfully my only pa...\n",
       "3245       None  TL;DR: Thank you for confirming some mismatch ...\n",
       "\n",
       "[3246 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = reranker.compute_score(pairs[:30])\n",
    "rankings = pd.DataFrame([scores, comments.text]).T\n",
    "rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"avsolatorio/NoInstruct-small-Embedding-v0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avsolatorio/NoInstruct-small-Embedding-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: Union[str, list[str]], mode: str = \"sentence\"):\n",
    "    model.eval()\n",
    "\n",
    "    assert mode in (\"query\", \"sentence\"), f\"mode={mode} was passed but only `query` and `sentence` are the supported modes.\"\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inp)\n",
    "\n",
    "    # The model is optimized to use the mean pooling for queries,\n",
    "    # while the sentence / document embedding uses the [CLS] representation.\n",
    "\n",
    "    if mode == \"query\":\n",
    "        vectors = output.last_hidden_state * inp[\"attention_mask\"].unsqueeze(2)\n",
    "        vectors = vectors.sum(dim=1) / inp[\"attention_mask\"].sum(dim=-1).view(-1, 1)\n",
    "    else:\n",
    "        vectors = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embedding(comments.text.tolist(), mode=\"sentence\")\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "torch.save(embeddings, f\"out/comments_embeddings-noInstructSmall_{timestamp}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the retrieval performance.\n",
    "query = get_embedding(\"How can I find product market fit?\", mode=\"query\")\n",
    "\n",
    "scores = F.cosine_similarity(query, embeddings, dim=-1)\n",
    "# print(scores.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>0.916152</td>\n",
       "      <td>Product Market Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>0.916152</td>\n",
       "      <td>Product Market Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>0.882274</td>\n",
       "      <td>Product Market Fit. Basically, can you find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>0.860962</td>\n",
       "      <td>Thank you for response. Recently I found blog ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.85509</td>\n",
       "      <td>Itâ€™s always product market fit. If the product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0.846613</td>\n",
       "      <td>Is that marketing (advertising) or product mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0.845904</td>\n",
       "      <td>Thank you so much for taking the time to answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0.844424</td>\n",
       "      <td>Great point! And if you see, that there are al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.840863</td>\n",
       "      <td>Yeah, possibly. I have only visibility to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.827746</td>\n",
       "      <td>I appreciate this viewpoint.&lt;p&gt;Thereâ€™s also a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score                                               text\n",
       "1481  0.916152                                 Product Market Fit\n",
       "1479  0.916152                                 Product Market Fit\n",
       "1480  0.882274  Product Market Fit. Basically, can you find th...\n",
       "3199  0.860962  Thank you for response. Recently I found blog ...\n",
       "1033   0.85509  Itâ€™s always product market fit. If the product...\n",
       "2972  0.846613  Is that marketing (advertising) or product mar...\n",
       "2050  0.845904  Thank you so much for taking the time to answe...\n",
       "1362  0.844424  Great point! And if you see, that there are al...\n",
       "460   0.840863  Yeah, possibly. I have only visibility to the ...\n",
       "2018  0.827746  I appreciate this viewpoint.<p>Thereâ€™s also a ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = pd.DataFrame([scores.cpu().numpy(), comments.text]).T\n",
    "rankings.columns = ['score', 'text']\n",
    "rankings.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['BAAI/bge-base-en-v1.5', 'BAAI/bge-small-en-v1.5']\n",
    "embedder = FlagModel(models[1], use_fp16=import pandas as pddasdfdasdfasdfddimport pandas saTrue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
