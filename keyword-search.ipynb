{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: google-genai in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (2.37.0)\n",
      "Requirement already satisfied: websockets<15.0dev,>=13.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (14.1)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (11.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (2.10.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas google-genai numpy tiktoken nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\Documents\\Projects\\hn-analysis\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import html\n",
    "import nltk\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>by</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>top_level_parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>kids</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>41813381</td>\n",
       "      <td>comment</td>\n",
       "      <td>marcosdumay</td>\n",
       "      <td>2024-10-11 20:26:21</td>\n",
       "      <td>None</td>\n",
       "      <td>Add forced sedentarism into that set.&lt;p&gt;This i...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41812891.0</td>\n",
       "      <td>41811263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>41813382</td>\n",
       "      <td>story</td>\n",
       "      <td>turkeynecks</td>\n",
       "      <td>2024-10-11 20:26:24</td>\n",
       "      <td>Mini DOOM-like FPS in BooBoo programming language</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indiedb.com/games/doomed1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41813382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>41813383</td>\n",
       "      <td>comment</td>\n",
       "      <td>davio</td>\n",
       "      <td>2024-10-11 20:26:28</td>\n",
       "      <td>None</td>\n",
       "      <td>hims sells the generic version for a fraction ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41813102.0</td>\n",
       "      <td>41811263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     type           by                time  \\\n",
       "999996  41813381  comment  marcosdumay 2024-10-11 20:26:21   \n",
       "999997  41813382    story  turkeynecks 2024-10-11 20:26:24   \n",
       "999998  41813383  comment        davio 2024-10-11 20:26:28   \n",
       "\n",
       "                                                    title  \\\n",
       "999996                                               None   \n",
       "999997  Mini DOOM-like FPS in BooBoo programming language   \n",
       "999998                                               None   \n",
       "\n",
       "                                                     text  \\\n",
       "999996  Add forced sedentarism into that set.<p>This i...   \n",
       "999997                                               None   \n",
       "999998  hims sells the generic version for a fraction ...   \n",
       "\n",
       "                                          url  score      parent  \\\n",
       "999996                                   None    NaN  41812891.0   \n",
       "999997  https://www.indiedb.com/games/doomed1    1.0         NaN   \n",
       "999998                                   None    NaN  41813102.0   \n",
       "\n",
       "        top_level_parent  descendants  kids deleted  dead  \n",
       "999996          41811263          NaN  None    None  None  \n",
       "999997          41813382          0.0  None    None  None  \n",
       "999998          41811263          NaN  None    None  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"OpenPipe/hacker-news\") # streaming=True\n",
    "df = pd.DataFrame(ds['train'][-1_000_000:-1])\n",
    "\n",
    "stories = df[df.type == 'story']\n",
    "comments = df[df.type == 'comment']\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_21508\\678916102.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments['low_quality'] = comments.text.map(lambda x: x in bad_comment) | comments.text.isna()\n"
     ]
    }
   ],
   "source": [
    "bad_comment = ['[flagged]', '[dead]', 'Thanks!', 'Thank you!', 'Yes.', 'No.', 'Yes', 'No', 'Thanks', 'Thank you']\n",
    "comments['low_quality'] = comments.text.map(lambda x: x in bad_comment) | comments.text.isna()\n",
    "comments = comments[~comments.low_quality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['text'] = comments.text.map(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase, remove punctuation, remove stop words, and lemmatize text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Handle non-string values\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['clean_text'] = comments['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822993"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['startup_founder_issues', 'specific_tools_methodologies', 'critiques_of_market_research', 'jobs_to_be_done', 'market_research_terms', 'overlapping_terms', 'customer_interviews_terms', 'product_validation_terms'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keywords import HnKeywords\n",
    "keywords = HnKeywords.as_dict()\n",
    "keywords.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startup_founder_issues': ['launching startup',\n",
       "  'idea validation',\n",
       "  'getting first customer',\n",
       "  'go market strategy',\n",
       "  'startup pain point',\n",
       "  'building mvp',\n",
       "  'startup mistake'],\n",
       " 'specific_tools_methodologies': ['google form',\n",
       "  'typeform',\n",
       "  'surveymonkey',\n",
       "  'dovetail',\n",
       "  'qualitative analysis software',\n",
       "  'nvivo'],\n",
       " 'critiques_of_market_research': ['useless customer interview',\n",
       "  'bad user research',\n",
       "  'outdated market research',\n",
       "  'time consuming research',\n",
       "  'market research bias',\n",
       "  'biased user feedback',\n",
       "  'flaw market analysis',\n",
       "  'expensive market research',\n",
       "  'market research broken',\n",
       "  'ineffective feedback',\n",
       "  'problem market research'],\n",
       " 'jobs_to_be_done': ['job customer hire product',\n",
       "  'job done case study',\n",
       "  'understanding job',\n",
       "  'job done framework',\n",
       "  'jtbd implementation',\n",
       "  'jtbd example'],\n",
       " 'market_research_terms': ['market trend',\n",
       "  'market segmentation strategy',\n",
       "  'competitive benchmarking',\n",
       "  'understanding market dynamic',\n",
       "  'market research report',\n",
       "  'market analysis',\n",
       "  'market gap',\n",
       "  'understanding user behavior',\n",
       "  'identifying competitor',\n",
       "  'analyzing market',\n",
       "  'competitive landscape',\n",
       "  'customer demographic analysis',\n",
       "  'primary research',\n",
       "  'market sizing',\n",
       "  'competitive analysis',\n",
       "  'understanding target market',\n",
       "  'examining market data',\n",
       "  'market research',\n",
       "  'customer segmentation',\n",
       "  'potential market size',\n",
       "  'understanding market size',\n",
       "  'focus group',\n",
       "  'identifying market need',\n",
       "  'understanding customer behavior',\n",
       "  'market opportunity assessment',\n",
       "  'identifying business opportunity',\n",
       "  'market trend insight',\n",
       "  'looking market trend',\n",
       "  'market survey',\n",
       "  'market opportunity',\n",
       "  'secondary research',\n",
       "  'industry research',\n",
       "  'target market analysis',\n",
       "  'market data analysis',\n",
       "  'market research finding',\n",
       "  'investigating competitive environment',\n",
       "  'industry analysis',\n",
       "  'analyzing competitor strength weakness'],\n",
       " 'overlapping_terms': ['user insight',\n",
       "  'understanding user',\n",
       "  'customer feedback',\n",
       "  'validating problem',\n",
       "  'understanding customer',\n",
       "  'need assessment',\n",
       "  'iterative feedback process',\n",
       "  'testing assumption',\n",
       "  'collecting user story',\n",
       "  'user feedback',\n",
       "  'product discovery',\n",
       "  'pain point',\n",
       "  'user preference',\n",
       "  'user research',\n",
       "  'customer insight',\n",
       "  'collecting customer story',\n",
       "  'validating approach',\n",
       "  'problem validation',\n",
       "  'early feedback',\n",
       "  'understanding user problem',\n",
       "  'product feedback',\n",
       "  'jtbd',\n",
       "  'understanding customer problem',\n",
       "  'customer preference',\n",
       "  'job done',\n",
       "  'feedback analysis',\n",
       "  'feedback idea'],\n",
       " 'customer_interviews_terms': ['customer pain point',\n",
       "  'customer say',\n",
       "  'remote interview',\n",
       "  'understanding customer need',\n",
       "  'qualitative interview',\n",
       "  'conducting customer interview',\n",
       "  'user interview',\n",
       "  'understanding user need',\n",
       "  'user feedback session',\n",
       "  'virtual interview',\n",
       "  'listening user',\n",
       "  'talking user',\n",
       "  'deep dive interview',\n",
       "  'user research study',\n",
       "  'collecting customer feedback',\n",
       "  'customer dialogue',\n",
       "  'speaking customer',\n",
       "  'feedback customer',\n",
       "  'oneonone interview',\n",
       "  'inperson interview',\n",
       "  'user interview analysis',\n",
       "  'interviewing potential user',\n",
       "  'user pain point',\n",
       "  '11 interview',\n",
       "  'customer interview',\n",
       "  'user conversation',\n",
       "  'user say',\n",
       "  'speaking user',\n",
       "  'analyzing user feedback',\n",
       "  'customer experience research',\n",
       "  'analyzing customer feedback',\n",
       "  'user dialogue',\n",
       "  'customer research study',\n",
       "  'customer story',\n",
       "  'exploring user need',\n",
       "  'user discovery',\n",
       "  'listening customer',\n",
       "  'customer insight gathering',\n",
       "  'conducting user interview',\n",
       "  'customer feedback session',\n",
       "  'customer discovery',\n",
       "  'asking user need',\n",
       "  'customer conversation',\n",
       "  'interviewing process',\n",
       "  'interview transcript',\n",
       "  'voice customer',\n",
       "  'feedback user',\n",
       "  'exploring customer need',\n",
       "  'user experience research',\n",
       "  'asking customer need',\n",
       "  'voc feedback',\n",
       "  'customer interview analysis',\n",
       "  'user insight gathering',\n",
       "  'talking customer',\n",
       "  'gathering user feedback',\n",
       "  'interviewing potential customer'],\n",
       " 'product_validation_terms': ['hypothesis testing',\n",
       "  'product market fit',\n",
       "  'pmf',\n",
       "  'minimum viable product',\n",
       "  'product validation',\n",
       "  'collecting feedback prototype',\n",
       "  'refining product based feedback',\n",
       "  'validating solution',\n",
       "  'validating value proposition',\n",
       "  'testing product usability',\n",
       "  'evaluating product performance',\n",
       "  'initial product feedback',\n",
       "  'finding productmarket fit',\n",
       "  'idea validation',\n",
       "  'product viable',\n",
       "  'validating assumption',\n",
       "  'feature validation',\n",
       "  'testing assumption user',\n",
       "  'early user testing',\n",
       "  'validating market demand',\n",
       "  'early product feedback',\n",
       "  'usability testing',\n",
       "  'customer feedback product',\n",
       "  'testing hypothesis',\n",
       "  'testing assumption customer',\n",
       "  'product useful',\n",
       "  'iterating product',\n",
       "  'validating product idea',\n",
       "  'user feedback product',\n",
       "  'user acceptance testing',\n",
       "  'concept testing',\n",
       "  'product feedback loop',\n",
       "  'testing product market hypothesis',\n",
       "  'testing product fit']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms = dict()\n",
    "for label, phrases in keywords.items():\n",
    "    clean = [preprocess_text(phrase) for phrase in phrases]\n",
    "    search_terms[label] = list(set(clean))\n",
    "search_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(corpus, queries, pbar=None):\n",
    "    \"\"\"Returns a boolean mask for rows that contain any of the given queries.\"\"\"\n",
    "    if not queries:\n",
    "        if pbar is not None:\n",
    "            pbar.update(0)\n",
    "        return pd.Series(False, index=corpus.index)\n",
    "    \n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(q) for q in queries) + r')\\b'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    mask = corpus.str.contains(compiled_pattern, na=False)\n",
    "    if pbar is not None:\n",
    "        pbar.update(len(queries))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [01:22<00:00,  2.24queries/s]\n"
     ]
    }
   ],
   "source": [
    "total_query_count = sum(len(terms) for terms in search_terms.values())\n",
    "pbar = tqdm(total=total_query_count, unit='queries')\n",
    "\n",
    "comments['labels'] = [[] for _ in range(len(comments))]\n",
    "\n",
    "# 3. For each category, find rows that match the category queries\n",
    "for category, queries in search_terms.items():\n",
    "    mask = keyword_search(comments['clean_text'], queries, pbar=pbar)\n",
    "    # Append the category label to each matching row's 'labels' list\n",
    "    comments.loc[mask, 'labels'] = comments.loc[mask, 'labels'].apply(\n",
    "        lambda current_list: current_list + [category]\n",
    "    )\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles the comment IDs and their matches\n",
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "comments['labels_str'] = comments['labels'].apply(lambda labels: '|'.join(labels))\n",
    "comments_with_labels = comments[comments['labels_str'] != '']\n",
    "comments_with_labels[['id', 'labels_str']].to_csv(\n",
    "    f'out/comments_with_labels_{timestamp}.csv', index=False\n",
    ")\n",
    "SAVED_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Load the most recent CSV file\n",
    "if not SAVED_DATA:\n",
    "    list_of_files = glob.glob('out/comments_with_labels_*.csv')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    comments_with_labels = pd.read_csv(latest_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>by</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>top_level_parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>kids</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40814477</td>\n",
       "      <td>comment</td>\n",
       "      <td>freedomben</td>\n",
       "      <td>2024-06-27 20:02:27</td>\n",
       "      <td>None</td>\n",
       "      <td>I&amp;#x27;ve struggled philosophically with that ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40814409.0</td>\n",
       "      <td>40812695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40814535, 40818971, 40814580]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40815826</td>\n",
       "      <td>comment</td>\n",
       "      <td>whit537</td>\n",
       "      <td>2024-06-27 22:21:59</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes! We aim to launch &lt;a href=\"https:&amp;#x2F;&amp;#x...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40815121.0</td>\n",
       "      <td>40810949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40816458</td>\n",
       "      <td>comment</td>\n",
       "      <td>al_borland</td>\n",
       "      <td>2024-06-27 23:53:51</td>\n",
       "      <td>None</td>\n",
       "      <td>One I thought was kind of silly that I made wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40816400.0</td>\n",
       "      <td>40816400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40816541</td>\n",
       "      <td>comment</td>\n",
       "      <td>kragen</td>\n",
       "      <td>2024-06-28 00:10:10</td>\n",
       "      <td>None</td>\n",
       "      <td>you ask what i mean about programmer productiv...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40812631.0</td>\n",
       "      <td>40804122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40817362, 40817247]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40818011</td>\n",
       "      <td>comment</td>\n",
       "      <td>canpan</td>\n",
       "      <td>2024-06-28 05:29:58</td>\n",
       "      <td>None</td>\n",
       "      <td>I use it for similar reasons! But I do not hav...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40817724.0</td>\n",
       "      <td>40817199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40819480, 40818194]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>41809964</td>\n",
       "      <td>comment</td>\n",
       "      <td>tivert</td>\n",
       "      <td>2024-10-11 14:49:22</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;gt; &amp;quot;We&amp;#x27;ll know our disinformation ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41809578.0</td>\n",
       "      <td>41807121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>specific_tools_methodologies</td>\n",
       "      <td>[specific_tools_methodologies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>41810229</td>\n",
       "      <td>comment</td>\n",
       "      <td>makowskid</td>\n",
       "      <td>2024-10-11 15:16:01</td>\n",
       "      <td>None</td>\n",
       "      <td>For the last couple of months, I&amp;#x27;m workin...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41690087.0</td>\n",
       "      <td>41690087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>41810632</td>\n",
       "      <td>comment</td>\n",
       "      <td>ranger_danger</td>\n",
       "      <td>2024-10-11 15:56:36</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;gt; didn&amp;#x27;t need H100s&lt;p&gt;I think we&amp;#x27;...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41806368.0</td>\n",
       "      <td>41805446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>41811404</td>\n",
       "      <td>comment</td>\n",
       "      <td>jauntywundrkind</td>\n",
       "      <td>2024-10-11 17:22:37</td>\n",
       "      <td>None</td>\n",
       "      <td>Still a shit poor pathetic excuse to screw ove...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41811226.0</td>\n",
       "      <td>41809698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41811540]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>customer_interviews_terms</td>\n",
       "      <td>[customer_interviews_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>41812600</td>\n",
       "      <td>comment</td>\n",
       "      <td>UniverseHacker</td>\n",
       "      <td>2024-10-11 19:18:02</td>\n",
       "      <td>None</td>\n",
       "      <td>It is not in any way related to my own area of...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41812445.0</td>\n",
       "      <td>41811263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>market_research_terms</td>\n",
       "      <td>[market_research_terms]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     type               by                time title  \\\n",
       "0     40814477  comment       freedomben 2024-06-27 20:02:27  None   \n",
       "1     40815826  comment          whit537 2024-06-27 22:21:59  None   \n",
       "2     40816458  comment       al_borland 2024-06-27 23:53:51  None   \n",
       "3     40816541  comment           kragen 2024-06-28 00:10:10  None   \n",
       "4     40818011  comment           canpan 2024-06-28 05:29:58  None   \n",
       "...        ...      ...              ...                 ...   ...   \n",
       "1790  41809964  comment           tivert 2024-10-11 14:49:22  None   \n",
       "1791  41810229  comment        makowskid 2024-10-11 15:16:01  None   \n",
       "1792  41810632  comment    ranger_danger 2024-10-11 15:56:36  None   \n",
       "1793  41811404  comment  jauntywundrkind 2024-10-11 17:22:37  None   \n",
       "1794  41812600  comment   UniverseHacker 2024-10-11 19:18:02  None   \n",
       "\n",
       "                                                   text   url  score  \\\n",
       "0     I&#x27;ve struggled philosophically with that ...  None    NaN   \n",
       "1     Yes! We aim to launch <a href=\"https:&#x2F;&#x...  None    NaN   \n",
       "2     One I thought was kind of silly that I made wa...  None    NaN   \n",
       "3     you ask what i mean about programmer productiv...  None    NaN   \n",
       "4     I use it for similar reasons! But I do not hav...  None    NaN   \n",
       "...                                                 ...   ...    ...   \n",
       "1790  &gt; &quot;We&#x27;ll know our disinformation ...  None    NaN   \n",
       "1791  For the last couple of months, I&#x27;m workin...  None    NaN   \n",
       "1792  &gt; didn&#x27;t need H100s<p>I think we&#x27;...  None    NaN   \n",
       "1793  Still a shit poor pathetic excuse to screw ove...  None    NaN   \n",
       "1794  It is not in any way related to my own area of...  None    NaN   \n",
       "\n",
       "          parent  top_level_parent  descendants  \\\n",
       "0     40814409.0          40812695          NaN   \n",
       "1     40815121.0          40810949          NaN   \n",
       "2     40816400.0          40816400          NaN   \n",
       "3     40812631.0          40804122          NaN   \n",
       "4     40817724.0          40817199          NaN   \n",
       "...          ...               ...          ...   \n",
       "1790  41809578.0          41807121          NaN   \n",
       "1791  41690087.0          41690087          NaN   \n",
       "1792  41806368.0          41805446          NaN   \n",
       "1793  41811226.0          41809698          NaN   \n",
       "1794  41812445.0          41811263          NaN   \n",
       "\n",
       "                                kids deleted  dead  \\\n",
       "0     [40814535, 40818971, 40814580]    None  None   \n",
       "1                               None    None  None   \n",
       "2                               None    None  None   \n",
       "3               [40817362, 40817247]    None  None   \n",
       "4               [40819480, 40818194]    None  None   \n",
       "...                              ...     ...   ...   \n",
       "1790                            None    None  None   \n",
       "1791                            None    None  None   \n",
       "1792                            None    None  None   \n",
       "1793                      [41811540]    None  None   \n",
       "1794                            None    None  None   \n",
       "\n",
       "                        labels_str                          labels  \n",
       "0                overlapping_terms             [overlapping_terms]  \n",
       "1                overlapping_terms             [overlapping_terms]  \n",
       "2                overlapping_terms             [overlapping_terms]  \n",
       "3                overlapping_terms             [overlapping_terms]  \n",
       "4                overlapping_terms             [overlapping_terms]  \n",
       "...                            ...                             ...  \n",
       "1790  specific_tools_methodologies  [specific_tools_methodologies]  \n",
       "1791             overlapping_terms             [overlapping_terms]  \n",
       "1792             overlapping_terms             [overlapping_terms]  \n",
       "1793     customer_interviews_terms     [customer_interviews_terms]  \n",
       "1794         market_research_terms         [market_research_terms]  \n",
       "\n",
       "[1795 rows x 16 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments = pd.merge(comments,\n",
    "                           comments_with_labels[['id', 'labels_str']],\n",
    "                           on='id',\n",
    "                           how='inner')\n",
    "labeled_comments['labels'] = labeled_comments['labels_str'].str.split('|')\n",
    "labeled_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_interviews_terms</th>\n",
       "      <th>jobs_to_be_done</th>\n",
       "      <th>market_research_terms</th>\n",
       "      <th>overlapping_terms</th>\n",
       "      <th>product_validation_terms</th>\n",
       "      <th>specific_tools_methodologies</th>\n",
       "      <th>startup_founder_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_interviews_terms</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobs_to_be_done</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_research_terms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlapping_terms</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1005</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_validation_terms</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specific_tools_methodologies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startup_founder_issues</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              customer_interviews_terms  jobs_to_be_done  \\\n",
       "customer_interviews_terms                           242                1   \n",
       "jobs_to_be_done                                       1                4   \n",
       "market_research_terms                                 1                0   \n",
       "overlapping_terms                                    34                1   \n",
       "product_validation_terms                              6                0   \n",
       "specific_tools_methodologies                          0                0   \n",
       "startup_founder_issues                                2                0   \n",
       "\n",
       "                              market_research_terms  overlapping_terms  \\\n",
       "customer_interviews_terms                         1                 34   \n",
       "jobs_to_be_done                                   0                  1   \n",
       "market_research_terms                           242                  5   \n",
       "overlapping_terms                                 5               1005   \n",
       "product_validation_terms                          1                  8   \n",
       "specific_tools_methodologies                      1                  4   \n",
       "startup_founder_issues                            0                  0   \n",
       "\n",
       "                              product_validation_terms  \\\n",
       "customer_interviews_terms                            6   \n",
       "jobs_to_be_done                                      0   \n",
       "market_research_terms                                1   \n",
       "overlapping_terms                                    8   \n",
       "product_validation_terms                           267   \n",
       "specific_tools_methodologies                         0   \n",
       "startup_founder_issues                               7   \n",
       "\n",
       "                              specific_tools_methodologies  \\\n",
       "customer_interviews_terms                                0   \n",
       "jobs_to_be_done                                          0   \n",
       "market_research_terms                                    1   \n",
       "overlapping_terms                                        4   \n",
       "product_validation_terms                                 0   \n",
       "specific_tools_methodologies                            76   \n",
       "startup_founder_issues                                   0   \n",
       "\n",
       "                              startup_founder_issues  \n",
       "customer_interviews_terms                          2  \n",
       "jobs_to_be_done                                    0  \n",
       "market_research_terms                              0  \n",
       "overlapping_terms                                  0  \n",
       "product_validation_terms                           7  \n",
       "specific_tools_methodologies                       0  \n",
       "startup_founder_issues                            26  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Collect all unique labels\n",
    "all_labels = sorted({lbl for row in labeled_comments['labels'] for lbl in row})\n",
    "\n",
    "# 2) Create a column for each label: 1 if present in 'labels', else 0\n",
    "for lbl in all_labels:\n",
    "    labeled_comments[lbl] = labeled_comments['labels'].apply(lambda row_labels: 1 if lbl in row_labels else 0)\n",
    "\n",
    "# 3) Build the co-occurrence matrix via dot-product\n",
    "#    This creates an NxN matrix where N = number of unique labels\n",
    "co_occ_matrix = labeled_comments[all_labels].T.dot(labeled_comments[all_labels])\n",
    "co_occ_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: read comments with interesting overlap - e.g. issues and customer interviews\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
