{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: google-genai in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (2.37.0)\n",
      "Requirement already satisfied: websockets<15.0dev,>=13.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (14.1)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (11.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-genai) (2.10.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\david\\documents\\projects\\hn-analysis\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas google-genai numpy tiktoken nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\Documents\\Projects\\hn-analysis\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "# import dask.dataframe as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import html\n",
    "import nltk\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>by</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>top_level_parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>kids</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>40813382</td>\n",
       "      <td>comment</td>\n",
       "      <td>pavon</td>\n",
       "      <td>2024-06-27 18:15:13</td>\n",
       "      <td>None</td>\n",
       "      <td>proto2 allowed both required fields and option...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40812948.0</td>\n",
       "      <td>40798740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40813554, 40816081]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>40813383</td>\n",
       "      <td>comment</td>\n",
       "      <td>ju-st</td>\n",
       "      <td>2024-06-27 18:15:15</td>\n",
       "      <td>None</td>\n",
       "      <td>Sorry I wasn&amp;#x27;t talking about density but ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40811561.0</td>\n",
       "      <td>40803783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>40813384</td>\n",
       "      <td>story</td>\n",
       "      <td>belter</td>\n",
       "      <td>2024-06-27 18:15:16</td>\n",
       "      <td>Astronauts take shelter in Starliner, other sp...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.space.com/iss-astronauts-shelter-r...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40813384</td>\n",
       "      <td>130.0</td>\n",
       "      <td>[40813633, 40815312, 40813760, 40813850, 40816...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     type      by                time  \\\n",
       "1999997  40813382  comment   pavon 2024-06-27 18:15:13   \n",
       "1999998  40813383  comment   ju-st 2024-06-27 18:15:15   \n",
       "1999999  40813384    story  belter 2024-06-27 18:15:16   \n",
       "\n",
       "                                                     title  \\\n",
       "1999997                                               None   \n",
       "1999998                                               None   \n",
       "1999999  Astronauts take shelter in Starliner, other sp...   \n",
       "\n",
       "                                                      text  \\\n",
       "1999997  proto2 allowed both required fields and option...   \n",
       "1999998  Sorry I wasn&#x27;t talking about density but ...   \n",
       "1999999                                               None   \n",
       "\n",
       "                                                       url  score      parent  \\\n",
       "1999997                                               None    NaN  40812948.0   \n",
       "1999998                                               None    NaN  40811561.0   \n",
       "1999999  https://www.space.com/iss-astronauts-shelter-r...  130.0         NaN   \n",
       "\n",
       "         top_level_parent  descendants  \\\n",
       "1999997          40798740          NaN   \n",
       "1999998          40803783          NaN   \n",
       "1999999          40813384        130.0   \n",
       "\n",
       "                                                      kids deleted  dead  \n",
       "1999997                               [40813554, 40816081]    None  None  \n",
       "1999998                                               None    None  None  \n",
       "1999999  [40813633, 40815312, 40813760, 40813850, 40816...    None  None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_parquet('hf://datasets/OpenPipe/hacker-news')\n",
    "ds = load_dataset(\"OpenPipe/hacker-news\") # streaming=True\n",
    "df = pd.DataFrame(ds['train'][-3_000_000:-1_000_000])\n",
    "\n",
    "stories = df[df.type == 'story']\n",
    "comments = df[df.type == 'comment']\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_31540\\678916102.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments['low_quality'] = comments.text.map(lambda x: x in bad_comment) | comments.text.isna()\n"
     ]
    }
   ],
   "source": [
    "bad_comment = ['[flagged]', '[dead]', 'Thanks!', 'Thank you!', 'Yes.', 'No.', 'Yes', 'No', 'Thanks', 'Thank you']\n",
    "comments['low_quality'] = comments.text.map(lambda x: x in bad_comment) | comments.text.isna()\n",
    "comments = comments[~comments.low_quality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['text'] = comments.text.map(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase, remove punctuation, remove stop words, and lemmatize text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Handle non-string values\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['clean_text'] = comments['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1690439"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['startup_founder_issues', 'specific_tools_methodologies', 'critiques_of_market_research', 'jobs_to_be_done', 'market_research', 'overlapping_terms', 'customer_interviews', 'product_validation', 'books'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keywords import HnKeywords\n",
    "keywords = HnKeywords.as_dict()\n",
    "keywords.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startup_founder_issues': ['getting first customer',\n",
       "  'launching startup',\n",
       "  'startup pain point',\n",
       "  'startup mistake',\n",
       "  'go market strategy',\n",
       "  'idea validation',\n",
       "  'building mvp'],\n",
       " 'specific_tools_methodologies': ['qualitative analysis software',\n",
       "  'nvivo',\n",
       "  'google form',\n",
       "  'typeform',\n",
       "  'dovetail',\n",
       "  'surveymonkey'],\n",
       " 'critiques_of_market_research': ['useless customer interview',\n",
       "  'expensive market research',\n",
       "  'ineffective feedback',\n",
       "  'flaw market analysis',\n",
       "  'problem market research',\n",
       "  'time consuming research',\n",
       "  'market research bias',\n",
       "  'outdated market research',\n",
       "  'market research broken',\n",
       "  'biased user feedback',\n",
       "  'bad user research'],\n",
       " 'jobs_to_be_done': ['jtbd implementation',\n",
       "  'understanding job',\n",
       "  'job done case study',\n",
       "  'job done framework',\n",
       "  'jtbd example',\n",
       "  'job customer hire product'],\n",
       " 'market_research': ['market gap',\n",
       "  'market trend',\n",
       "  'analyzing market',\n",
       "  'understanding market size',\n",
       "  'market research report',\n",
       "  'focus group',\n",
       "  'competitive landscape',\n",
       "  'potential market size',\n",
       "  'identifying competitor',\n",
       "  'market research finding',\n",
       "  'understanding target market',\n",
       "  'analyzing competitor strength weakness',\n",
       "  'understanding customer behavior',\n",
       "  'market research',\n",
       "  'market opportunity assessment',\n",
       "  'competitive benchmarking',\n",
       "  'market segmentation strategy',\n",
       "  'market analysis',\n",
       "  'competitive analysis',\n",
       "  'looking market trend',\n",
       "  'market data analysis',\n",
       "  'customer demographic analysis',\n",
       "  'understanding market dynamic',\n",
       "  'examining market data',\n",
       "  'identifying market need',\n",
       "  'industry research',\n",
       "  'market survey',\n",
       "  'primary research',\n",
       "  'identifying business opportunity',\n",
       "  'investigating competitive environment',\n",
       "  'market trend insight',\n",
       "  'customer segmentation',\n",
       "  'market sizing',\n",
       "  'market opportunity',\n",
       "  'target market analysis',\n",
       "  'industry analysis',\n",
       "  'secondary research',\n",
       "  'understanding user behavior'],\n",
       " 'overlapping_terms': ['feedback analysis',\n",
       "  'product discovery',\n",
       "  'validating approach',\n",
       "  'testing assumption',\n",
       "  'user insight',\n",
       "  'iterative feedback process',\n",
       "  'customer insight',\n",
       "  'problem validation',\n",
       "  'pain point',\n",
       "  'collecting customer story',\n",
       "  'job done',\n",
       "  'collecting user story',\n",
       "  'feedback idea',\n",
       "  'validating problem',\n",
       "  'jtbd',\n",
       "  'user research',\n",
       "  'understanding user',\n",
       "  'need assessment',\n",
       "  'understanding user problem',\n",
       "  'understanding customer',\n",
       "  'understanding customer problem'],\n",
       " 'customer_interviews': ['user discovery',\n",
       "  'feedback user',\n",
       "  'user insight gathering',\n",
       "  'remote interview',\n",
       "  'conducting user interview',\n",
       "  'interview transcript',\n",
       "  'asking customer need',\n",
       "  'inperson interview',\n",
       "  'oneonone interview',\n",
       "  'exploring customer need',\n",
       "  'deep dive interview',\n",
       "  'understanding user need',\n",
       "  'gathering user feedback',\n",
       "  'speaking user',\n",
       "  'user conversation',\n",
       "  'voc feedback',\n",
       "  'feedback customer',\n",
       "  'talking customer',\n",
       "  'user interview',\n",
       "  'customer experience research',\n",
       "  'understanding customer need',\n",
       "  'exploring user need',\n",
       "  'analyzing user feedback',\n",
       "  'speaking customer',\n",
       "  'customer interview analysis',\n",
       "  'customer say',\n",
       "  'customer conversation',\n",
       "  'listening user',\n",
       "  'conducting customer interview',\n",
       "  'customer insight gathering',\n",
       "  'user research study',\n",
       "  'user experience research',\n",
       "  'analyzing customer feedback',\n",
       "  'customer story',\n",
       "  'user dialogue',\n",
       "  'user say',\n",
       "  'user interview analysis',\n",
       "  '11 interview',\n",
       "  'user feedback session',\n",
       "  'customer dialogue',\n",
       "  'virtual interview',\n",
       "  'user pain point',\n",
       "  'interviewing potential user',\n",
       "  'customer discovery',\n",
       "  'customer feedback session',\n",
       "  'interviewing potential customer',\n",
       "  'customer research study',\n",
       "  'voice customer',\n",
       "  'qualitative interview',\n",
       "  'collecting customer feedback',\n",
       "  'customer interview',\n",
       "  'listening customer',\n",
       "  'interviewing process',\n",
       "  'customer pain point',\n",
       "  'asking user need',\n",
       "  'talking user'],\n",
       " 'product_validation': ['early product feedback',\n",
       "  'testing product fit',\n",
       "  'idea validation',\n",
       "  'user acceptance testing',\n",
       "  'product hypothesis',\n",
       "  'validating product idea',\n",
       "  'validating market demand',\n",
       "  'usability testing',\n",
       "  'testing product usability',\n",
       "  'evaluating product performance',\n",
       "  'validating value proposition',\n",
       "  'feature validation',\n",
       "  'testing hypothesis',\n",
       "  'early user testing',\n",
       "  'refining product based feedback',\n",
       "  'testing assumption user',\n",
       "  'testing product market hypothesis',\n",
       "  'validating solution',\n",
       "  'market hypothesis',\n",
       "  'concept testing',\n",
       "  'hypothesis testing',\n",
       "  'iterating product',\n",
       "  'customer feedback product',\n",
       "  'validating assumption',\n",
       "  'product viable',\n",
       "  'testing assumption customer',\n",
       "  'finding productmarket fit',\n",
       "  'product market fit',\n",
       "  'product validation',\n",
       "  'user feedback product',\n",
       "  'product useful',\n",
       "  'minimum viable product',\n",
       "  'pmf',\n",
       "  'product feedback loop',\n",
       "  'initial product feedback',\n",
       "  'collecting feedback prototype'],\n",
       " 'books': ['lean startup',\n",
       "  'statue stone',\n",
       "  'lean product playbook',\n",
       "  'lean customer development',\n",
       "  'mom test',\n",
       "  'zero one']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms = dict()\n",
    "for label, phrases in keywords.items():\n",
    "    clean = [preprocess_text(phrase) for phrase in phrases]\n",
    "    search_terms[label] = list(set(clean))\n",
    "search_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(corpus, queries, pbar=None):\n",
    "    \"\"\"Returns a boolean mask for rows that contain any of the given queries.\"\"\"\n",
    "    if not queries:\n",
    "        if pbar is not None:\n",
    "            pbar.update(0)\n",
    "        return pd.Series(False, index=corpus.index)\n",
    "    \n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(q) for q in queries) + r')\\b'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    mask = corpus.str.contains(compiled_pattern, na=False)\n",
    "    if pbar is not None:\n",
    "        pbar.update(len(queries))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [02:48<00:00,  1.11queries/s]\n"
     ]
    }
   ],
   "source": [
    "total_query_count = sum(len(terms) for terms in search_terms.values())\n",
    "pbar = tqdm(total=total_query_count, unit='queries')\n",
    "\n",
    "comments['labels'] = [[] for _ in range(len(comments))]\n",
    "\n",
    "# 3. For each category, find rows that match the category queries\n",
    "for category, queries in search_terms.items():\n",
    "    mask = keyword_search(comments['clean_text'], queries, pbar=pbar)\n",
    "    # Append the category label to each matching row's 'labels' list\n",
    "    comments.loc[mask, 'labels'] = comments.loc[mask, 'labels'].apply(\n",
    "        lambda current_list: current_list + [category]\n",
    "    )\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles the comment IDs and their matches\n",
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "comments['labels_str'] = comments['labels'].apply(lambda labels: '|'.join(labels))\n",
    "comments_with_labels = comments[comments['labels_str'] != '']\n",
    "comments_with_labels[['id', 'labels_str']].to_csv(\n",
    "    f'out/comments_with_labels_{timestamp}.csv', index=False\n",
    ")\n",
    "SAVED_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Load the most recent CSV file\n",
    "list_of_files = glob.glob('out/comments_with_labels_*.csv')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "comments_with_labels = pd.read_csv(latest_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>by</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>top_level_parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>kids</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38813410</td>\n",
       "      <td>comment</td>\n",
       "      <td>willis936</td>\n",
       "      <td>2023-12-30 07:27:01</td>\n",
       "      <td>None</td>\n",
       "      <td>Laziness is the enemy.  I spend a lot of time ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38812794.0</td>\n",
       "      <td>38812244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38813425</td>\n",
       "      <td>comment</td>\n",
       "      <td>kstrauser</td>\n",
       "      <td>2023-12-30 07:30:46</td>\n",
       "      <td>None</td>\n",
       "      <td>I just stuck it on a public server, behind a B...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38813361.0</td>\n",
       "      <td>38795735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[38823447]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     type         by                time title  \\\n",
       "0  38813410  comment  willis936 2023-12-30 07:27:01  None   \n",
       "1  38813425  comment  kstrauser 2023-12-30 07:30:46  None   \n",
       "\n",
       "                                                text   url  score      parent  \\\n",
       "0  Laziness is the enemy.  I spend a lot of time ...  None    NaN  38812794.0   \n",
       "1  I just stuck it on a public server, behind a B...  None    NaN  38813361.0   \n",
       "\n",
       "   top_level_parent  descendants        kids deleted  dead         labels_str  \\\n",
       "0          38812244          NaN        None    None  None  overlapping_terms   \n",
       "1          38795735          NaN  [38823447]    None  None  overlapping_terms   \n",
       "\n",
       "                labels  \n",
       "0  [overlapping_terms]  \n",
       "1  [overlapping_terms]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments = pd.merge(comments,\n",
    "                           comments_with_labels[['id', 'labels_str']],\n",
    "                           on='id',\n",
    "                           how='inner')\n",
    "if 'labels' not in labeled_comments:\n",
    "    labeled_comments['labels'] = labeled_comments['labels_str'].str.split('|')\n",
    "labeled_comments.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>books</th>\n",
       "      <th>critiques_of_market_research</th>\n",
       "      <th>customer_interviews</th>\n",
       "      <th>jobs_to_be_done</th>\n",
       "      <th>market_research</th>\n",
       "      <th>overlapping_terms</th>\n",
       "      <th>product_validation</th>\n",
       "      <th>specific_tools_methodologies</th>\n",
       "      <th>startup_founder_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critiques_of_market_research</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_interviews</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobs_to_be_done</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_research</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlapping_terms</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1477</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_validation</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specific_tools_methodologies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startup_founder_issues</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              books  critiques_of_market_research  \\\n",
       "books                           180                             0   \n",
       "critiques_of_market_research      0                             2   \n",
       "customer_interviews               2                             0   \n",
       "jobs_to_be_done                   0                             0   \n",
       "market_research                   1                             1   \n",
       "overlapping_terms                 2                             1   \n",
       "product_validation                2                             0   \n",
       "specific_tools_methodologies      0                             0   \n",
       "startup_founder_issues            1                             0   \n",
       "\n",
       "                              customer_interviews  jobs_to_be_done  \\\n",
       "books                                           2                0   \n",
       "critiques_of_market_research                    0                0   \n",
       "customer_interviews                           564                0   \n",
       "jobs_to_be_done                                 0                9   \n",
       "market_research                                 8                0   \n",
       "overlapping_terms                              39                1   \n",
       "product_validation                              5                0   \n",
       "specific_tools_methodologies                    1                0   \n",
       "startup_founder_issues                          1                0   \n",
       "\n",
       "                              market_research  overlapping_terms  \\\n",
       "books                                       1                  2   \n",
       "critiques_of_market_research                1                  1   \n",
       "customer_interviews                         8                 39   \n",
       "jobs_to_be_done                             0                  1   \n",
       "market_research                           437                 18   \n",
       "overlapping_terms                          18               1477   \n",
       "product_validation                          7                  6   \n",
       "specific_tools_methodologies                1                  0   \n",
       "startup_founder_issues                      1                  2   \n",
       "\n",
       "                              product_validation  \\\n",
       "books                                          2   \n",
       "critiques_of_market_research                   0   \n",
       "customer_interviews                            5   \n",
       "jobs_to_be_done                                0   \n",
       "market_research                                7   \n",
       "overlapping_terms                              6   \n",
       "product_validation                           460   \n",
       "specific_tools_methodologies                   0   \n",
       "startup_founder_issues                        12   \n",
       "\n",
       "                              specific_tools_methodologies  \\\n",
       "books                                                    0   \n",
       "critiques_of_market_research                             0   \n",
       "customer_interviews                                      1   \n",
       "jobs_to_be_done                                          0   \n",
       "market_research                                          1   \n",
       "overlapping_terms                                        0   \n",
       "product_validation                                       0   \n",
       "specific_tools_methodologies                           161   \n",
       "startup_founder_issues                                   0   \n",
       "\n",
       "                              startup_founder_issues  \n",
       "books                                              1  \n",
       "critiques_of_market_research                       0  \n",
       "customer_interviews                                1  \n",
       "jobs_to_be_done                                    0  \n",
       "market_research                                    1  \n",
       "overlapping_terms                                  2  \n",
       "product_validation                                12  \n",
       "specific_tools_methodologies                       0  \n",
       "startup_founder_issues                            64  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Collect all unique labels\n",
    "all_labels = sorted({lbl for row in labeled_comments['labels'] for lbl in row})\n",
    "\n",
    "# 2) Create a column for each label: 1 if present in 'labels', else 0\n",
    "for lbl in all_labels:\n",
    "    labeled_comments[lbl] = labeled_comments['labels'].apply(lambda row_labels: 1 if lbl in row_labels else 0)\n",
    "\n",
    "# 3) Build the co-occurrence matrix via dot-product\n",
    "#    This creates an NxN matrix where N = number of unique labels\n",
    "co_occ_matrix = labeled_comments[all_labels].T.dot(labeled_comments[all_labels])\n",
    "co_occ_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save relevant comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "labels_file = f'out/full_labeled_comments_{timestamp}.parquet'\n",
    "labeled_comments.to_parquet(labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [entry\u001b[38;5;241m.\u001b[39mid]\n\u001b[1;32m---> 14\u001b[0m find_ancestors(\u001b[43mdf\u001b[49m,\u001b[38;5;241m41813270\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def find_ancestors(df, row_id) -> list[int]:\n",
    "    entry = df[df['id'] == int(row_id)]\n",
    "\n",
    "    if len(entry) == 0:\n",
    "        return []\n",
    "    elif len(entry) > 1:\n",
    "        raise ValueError(f\"Multiple rows with id {row_id}.\")\n",
    "    entry = entry.iloc[0]\n",
    "    if entry.parent > 0:\n",
    "        return [entry.id] + find_ancestors(df, entry.parent)\n",
    "    else:\n",
    "        return [entry.id]\n",
    "\n",
    "find_ancestors(df,41813270)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file saved to: out/comments_20250111_202454.html\n"
     ]
    }
   ],
   "source": [
    "import htmlgen\n",
    "\n",
    "htmlgen.create_html_from_comments(labeled_comments[['id', 'text', 'labels']], title=\" Hacker News Comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>by</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>top_level_parent</th>\n",
       "      <th>...</th>\n",
       "      <th>dead</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>labels</th>\n",
       "      <th>customer_interviews_terms</th>\n",
       "      <th>jobs_to_be_done</th>\n",
       "      <th>market_research_terms</th>\n",
       "      <th>overlapping_terms</th>\n",
       "      <th>product_validation_terms</th>\n",
       "      <th>specific_tools_methodologies</th>\n",
       "      <th>startup_founder_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40814477</td>\n",
       "      <td>comment</td>\n",
       "      <td>freedomben</td>\n",
       "      <td>2024-06-27 20:02:27</td>\n",
       "      <td>None</td>\n",
       "      <td>I&amp;#x27;ve struggled philosophically with that ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40814409.0</td>\n",
       "      <td>40812695</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40815826</td>\n",
       "      <td>comment</td>\n",
       "      <td>whit537</td>\n",
       "      <td>2024-06-27 22:21:59</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes! We aim to launch &lt;a href=\"https:&amp;#x2F;&amp;#x...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40815121.0</td>\n",
       "      <td>40810949</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40816458</td>\n",
       "      <td>comment</td>\n",
       "      <td>al_borland</td>\n",
       "      <td>2024-06-27 23:53:51</td>\n",
       "      <td>None</td>\n",
       "      <td>One I thought was kind of silly that I made wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40816400.0</td>\n",
       "      <td>40816400</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40816541</td>\n",
       "      <td>comment</td>\n",
       "      <td>kragen</td>\n",
       "      <td>2024-06-28 00:10:10</td>\n",
       "      <td>None</td>\n",
       "      <td>you ask what i mean about programmer productiv...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40812631.0</td>\n",
       "      <td>40804122</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40818011</td>\n",
       "      <td>comment</td>\n",
       "      <td>canpan</td>\n",
       "      <td>2024-06-28 05:29:58</td>\n",
       "      <td>None</td>\n",
       "      <td>I use it for similar reasons! But I do not hav...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40817724.0</td>\n",
       "      <td>40817199</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>overlapping_terms</td>\n",
       "      <td>[overlapping_terms]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     type          by                time title  \\\n",
       "0  40814477  comment  freedomben 2024-06-27 20:02:27  None   \n",
       "1  40815826  comment     whit537 2024-06-27 22:21:59  None   \n",
       "2  40816458  comment  al_borland 2024-06-27 23:53:51  None   \n",
       "3  40816541  comment      kragen 2024-06-28 00:10:10  None   \n",
       "4  40818011  comment      canpan 2024-06-28 05:29:58  None   \n",
       "\n",
       "                                                text   url  score      parent  \\\n",
       "0  I&#x27;ve struggled philosophically with that ...  None    NaN  40814409.0   \n",
       "1  Yes! We aim to launch <a href=\"https:&#x2F;&#x...  None    NaN  40815121.0   \n",
       "2  One I thought was kind of silly that I made wa...  None    NaN  40816400.0   \n",
       "3  you ask what i mean about programmer productiv...  None    NaN  40812631.0   \n",
       "4  I use it for similar reasons! But I do not hav...  None    NaN  40817724.0   \n",
       "\n",
       "   top_level_parent  ...  dead         labels_str               labels  \\\n",
       "0          40812695  ...  None  overlapping_terms  [overlapping_terms]   \n",
       "1          40810949  ...  None  overlapping_terms  [overlapping_terms]   \n",
       "2          40816400  ...  None  overlapping_terms  [overlapping_terms]   \n",
       "3          40804122  ...  None  overlapping_terms  [overlapping_terms]   \n",
       "4          40817199  ...  None  overlapping_terms  [overlapping_terms]   \n",
       "\n",
       "  customer_interviews_terms jobs_to_be_done market_research_terms  \\\n",
       "0                         0               0                     0   \n",
       "1                         0               0                     0   \n",
       "2                         0               0                     0   \n",
       "3                         0               0                     0   \n",
       "4                         0               0                     0   \n",
       "\n",
       "   overlapping_terms  product_validation_terms  specific_tools_methodologies  \\\n",
       "0                  1                         0                             0   \n",
       "1                  1                         0                             0   \n",
       "2                  1                         0                             0   \n",
       "3                  1                         0                             0   \n",
       "4                  1                         0                             0   \n",
       "\n",
       "   startup_founder_issues  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
